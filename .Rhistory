library(ggplot2)
search()
find_rtools()
install.packages("KernSmooth")
search()
library(KernSmooth)
getwd()
m <- 1:10
dim(m) <- c(4,5)
dim(m) <- c(2,5)
m
x <- factor(c(‘yes’, ‘yes’, ’no’n ‘yes’, ’no'))
x <- factor(c('yes', 'yes', 'no' 'yes', 'no'))
x <- factor(c(‘yes’, ‘yes’, ’no’, ‘yes’, ’no'))
x <- factor(c('yes', 'yes', 'no', 'yes', 'no'))
table(x)
unclass(x)
getwd()
setwd("./Dev/datasciencecoursera/data-cleaning/")
library("xslx")
library(xslx)
install.packages("xlsx")
library(xslx)
library(kernlab)
data(spam)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
trainSpam = spam[trainIndicator == 1,]
testSpam = spam[trainIndicator == 0,]
install.packages('kernlab')
library(kernlab)
data(spam)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
trainSpam = spam[trainIndicator == 1,]
testSpam = spam[trainIndicator == 0,]
testSpam
trainIndicator
table(trainIndicator)
names(trainSpam)
table(trainSpam$type)
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type) #difficult to read
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam$capitalAve) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1))
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
##Which predictor has minimum cross-validated error?
names(trainSpam)[which.min(cvError)]
## Use the best model from the group
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
## Get predictions ont the test set
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
## Classify as 'spam' for those with prob > 0.5
predictedSpam[predictionModel$fitted > 0.5] = "spam"
## Classification table
table(predictedSpam, testSpam$type)
## Error rate
(61 + 458)/(1346 + 458 + 61 + 449)
install.package("xtable")
install.packages("xtable")
source('~/.active-rstudio-document', echo=TRUE)
unzip("activity.zip")
unzip("./activity.zip")
unzip("./activity.zip")
getwd()
setwd("/Users/julienbalmont/Dev/datasciencecoursera/RepData_PeerAssessment1/")
unzip("./activity.zip")
file.path(".")
script.dir <- dirname(sys.frame(1)$ofile)
script.dir <- dirname(sys.frame(0)$ofile)
sys.frame
---
sys.frame(1)
unzip("./activity.zip")
data <- read.csv("./activity.csv")
data(data)
summary(data)
unzip("./activity.zip")
data <- read.csv("./activity.csv")
data(data)
summary(data)
activityData <- read.csv("./activity.csv")
data(activityData)
summary(activityData)
pairs(activityData)
table(activityData)
head(activityData)
?pair
?pairs
summary(activityData)
summary(aggregate(steps ~ date, activityData, sum))
stepsPerDay <- aggregate(steps ~ date, activityData, sum)
hist(stepsPerDay)
stepsPerDay <- aggregate(steps ~ date, activityData, sum)
hist(stepsPerDay$steps)
mean(totalSteps$steps)
mean(stepsPerDay$steps)
+ The mean total number of steps taken each day is **`r meanStepsPerDay`**
+ The median total number of steps taken each day is **`r medianStepsPerDay`**
meanStepsPerDay
stepsPerDay <- aggregate(steps ~ date, activityData, sum)
hist(stepsPerDay$steps)
meanStepsPerDay <- mean(stepsPerDay$steps)
meanStepsPerDay
medianStepsPerDay <- median(stepsPerDay$steps)
```
+ The mean total number of steps taken each day is **`r meanStepsPerDay`**
+ The median total number of steps taken each day is **`r medianStepsPerDay`**
